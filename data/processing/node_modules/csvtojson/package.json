{
  "name": "csvtojson",
  "description": "A tool concentrating on converting csv data to JSON with customised parser supporting",
  "author": {
    "name": "Keyang Xiang",
    "email": "keyang.xiang@gmail.com"
  },
  "homepage": "http://keyangxiang.com/blog/csv2json/",
  "bugs": {
    "url": "https://github.com/Keyang/node-csvtojson/issues"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/Keyang/node-csvtojson.git"
  },
  "contributors": [
    {
      "name": "Keyang Xiang",
      "email": "keyang.xiang@gmail.com"
    }
  ],
  "version": "0.1.7",
  "dependencies": {
    "express": "3.4.4",
    "csv": "0.3.6"
  },
  "keywords": [
    "csv",
    "json",
    "convert",
    "parser",
    "exntendible",
    "plugin"
  ],
  "bin": {
    "csvtojson": "./bin/csvtojson"
  },
  "readme": "#CSV2JSON\nAll you need nodejs csv to json converter. Support big json data, CLI, server. can be easily plugged and used in other nodejs app.\n\n##Menu\n* [Installation](#installation)\n* [Example](#example)\n* [Usage](#usage)\n    * [CLI Tool](#command-line-tools)\n    * [Web Service](#webservice)\n    * [API & Library](#api)\n        * [Quick Start](#quick-start)\n        * [Customised Parser](#parser)\n        * [Integrate with your express server](#webserver)\n        * [Events](#events)\n        * [Built-in Parsers](#default-parsers)\n        * [Example](#example)\n        * [Big CSV File Streaming](#big-csv-file)\n\nGitHub: https://github.com/Keyang/node-csvtojson\n\n##Installation\n>npm install -g csvtojson\n\n\n##Features\n\n* Powerful library for you nodejs applications processing csv data.\n* Extremly straight forward\n* Multiple input support: CSV File, Readable Stream, CSV String etc.\n* Highly extendible with your own rules and parsers for outputs.\n* Multiple interfaces (webservice, command line)\n \n\n##Usage\n\n###Command Line Tools\n\n>csvtojson [ CSVFilePath | StartServer]  [port]\n\nExample\n\n>csvtojson ./myCSVFile\n\nOr use pipe:\n\n>cat myCSVFile | csvtojson\n\nTo start a webserver\n\n>csvtojson startserver [port]\n\nDefault port number is 8801.\n\n### WebService\nAfter webserve being initialised, it is able to use http post with CSV data as body.\nFor example, we start web server with default configuration:\n>csvtojson startserver\n\nAnd then we use curl to perform a web request:\n>curl -X POST -d \"date,\\*json\\*employee.name,\\*json\\*employee.age,\\*json\\*employee.number,\\*array\\*address,\\*array\\*address,\\*jsonarray\\*employee.key,\\*jsonarray\\*employee.key,\\*omit\\*id\n>\n>2012-02-12,Eric,31,51234,Dunno Street,Kilkeny Road,key1,key2,2\n>\n>2012-03-06,Ted,28,51289,Cambridge Road,Tormore,key3,key4,4\" http://127.0.0.1:8801/parseCSV\n\n### API\nUse csvtojson library to your own project.\nImport csvtojson to your package.json or install through npm:\n>npm install csvtojson\n\n#### Quick Start\nThe core of the tool is Converter class. It is based on node-csv library (version 0.3.6). Therefore it has all features of [node-csv](http://www.adaltas.com/projects/node-csv/). To start a parse, simply use following code:\n\n```js\n//Converter Class\nvar Converter=require(\"csvtojson\").core.Converter;\n    \n//CSV File Path or CSV String or Readable Stream Object\nvar csvFileName=\"./myCSVFile\";\n    \n//new converter instance\nvar csvConverter=new Converter();\n    \n//end_parsed will be emitted once parsing finished\ncsvConverter.on(\"end_parsed\",function(jsonObj){\n   console.log(jsonObj); //here is your result json object\n});\n    \n//read from file\ncsvConverter.from(csvFileName);\n```\n\n#### Parser\nCSVTOJSON allows adding customised parsers which concentrating on what to parse and how to parse.\nIt is the main power of the tool that developer only needs to concentrate on how to deal with the data and other concerns like streaming, memory, web, cli etc are done automatically.\n\nHow to add a customised parser:\n\n```js\n//Parser Manager\nvar parserMgr=require(\"csvtojson\").core.parserMgr;\n\nparserMgr.addParser(\"myParserName\",/^\\*parserRegExp\\*/,function (params){\n   var columnTitle=params.head; //params.head be like: *parserRegExp*ColumnName;\n   var fieldName=columnTitle.replace(this.regExp, \"\"); //this.regExp is the regular expression above.\n   params.resultRow[fieldName]=\"Hello my parser\"+params.item;\n});\n```\n\nparserMgr's addParser function take three parameters:\n\n1. parser name: the name of your parser. It should be unique.\n\n2. Regular Expression: It is used to test if a column of CSV data is using this parser. In the example above any column's first row starting with *parserRegExp* will be using it.\n\n3. Parse function call back: It is where the parse happens. The converter works row by row and therefore the function will be called each time needs to parse a cell in CSV data.\n\nThe parameter of Parse function is a JSON object. It contains following fields:\n\n**head**: The column's first row's data. It generally contains field information. e.g. *array*items\n\n**item**: The data inside current cell.  e.g. item1\n\n**itemIndex**: the index of current cell of a row. e.g. 0\n\n**rawRow**: the reference of current row in array format. e.g. [\"item1\", 23 ,\"hello\"]\n\n**resultRow**: the reference of result row in JSON format. e.g. {\"name\":\"Joe\"}\n\n**rowIndex**: the index of current row in CSV data. start from 1 since 0 is the head. e.g. 1\n\n**resultObject**: the reference of result object in JSON format. It always has a field called csvRows which is in Array format. It changes as parsing going on. e.g. \n\n```json    \n{\n   \"csvRows\":[\n      {\n          \"itemName\":\"item1\",\n          \"number\":10\n      },\n      {\n         \"itemName\":\"item2\",\n         \"number\":4\n      }\n   ]\n}\n```\n\n#### WebServer\nIt is able to start the web server through code.\n\n```js\nvar webServer=require(\"csvtojson\").interfaces.web;\n\nvar expressApp=webServer.startWebServer({\n   \"port\":\"8801\",\n   \"urlPath\":\"/parseCSV\"\n});\n```\n\nIt will return an [expressjs](http://expressjs.com/) Application. You can add your own  web app content there.\n\nIf you already have an express application, simply use following code to extend your current application\n\n```js\nvar webServer=require(\"csvtojson\").interfaces.web;\n\n//..your code to setup the application object.\n\nwebServer.applyWebServer(app, postURL); //postURL can be omitted by using default one.\n```\n\n#### Events\n\nFollowing events are used for Converter class:\n\n* end_parsed: It is emitted when parsing finished. the callback function will contain the JSON object\n* record_parsed: it is emitted each time a row has been parsed. The callback function has following parameters: result row JSON object reference, Original row array object reference, row index\n\nTo subscribe the event:\n\n```js\n//Converter Class\nvar Converter=require(\"csvtojson\").core.Converter;\n    \n//end_parsed will be emitted once parsing finished\ncsvConverter.on(\"end_parsed\",function(jsonObj){\n    console.log(jsonObj); //here is your result json object\n});\n    \n//record_parsed will be emitted each time a row has been parsed.\ncsvConverter.on(\"record_parsed\",function(resultRow,rawRow,rowIndex){\n   console.log(resultRow); //here is your result json object\n});\n```\n\n#### Default Parsers\nThere are default parsers in the library they are\n\n**Array**: For columns head start with \"*array*\" e.g. \"*array*fieldName\", this parser will combine cells data with same fieldName to one Array.\n\n**Nested JSON**: For columns head start with \"*json*\" e.g. \"*json*my.nested.json.structure\", this parser will create nested nested JSON structure: my.nested.json\n\n**Nested JSON Array**: For columns head start with \"*jsonarray*\" e.g. \"*jsonarray*my.items\", this parser will create structure like my.items[].\n\n**Omitted column**: For columns head start with \"*omit*\" e.g. \"*omit*id\", the parser will omit the column's data.\n\n####Example:\n\nOriginal data:\n\n    date,*json*employee.name,*json*employee.age,*json*employee.number,*array*address,*array*address,*jsonarray*employee.key,*jsonarray*employee.key,*omit*id\n    2012-02-12,Eric,31,51234,Dunno Street,Kilkeny Road,key1,key2,2\n    2012-03-06,Ted,28,51289,Cambridge Road,Tormore,key3,key4,4\n\nOutput data:\n\n```json\n{\n   \"csvRows\": [\n      {\n         \"date\": \"2012-02-12\",\n         \"employee\": {\n            \"name\": \"Eric\",\n            \"age\": \"31\",\n            \"number\": \"51234\",\n            \"key\": [\n              \"key1\",\n              \"key2\"\n            ]\n          },\n          \"address\": [\n            \"Dunno Street\",\n            \"Kilkeny Road\"\n          ]\n        },\n        {\n          \"date\": \"2012-03-06\",\n          \"employee\": {\n            \"name\": \"Ted\",\n            \"age\": \"28\",\n            \"number\": \"51289\",\n            \"key\": [\n              \"key3\",\n              \"key4\"\n            ]\n         },\n         \"address\": [\n            \"Cambridge Road\",\n            \"Tormore\"\n         ]\n      }\n   ]\n}\n```\n#### Big CSV File\ncsvtojson library was designed to accept big csv file converting. To avoid memory consumption, it is recommending to use read stream and write stream. \n\n```js\nvar Converter=require(\"csvtojson\").core.Converter;\nvar csvConverter=new Converter(false); // The parameter false will turn off final result construction. It can avoid huge memory consumption while parsing. The trade off is final result will not be populated to end_parsed event.\n\nvar readStream=require(\"fs\").createReadStream(\"inputData.csv\"); \n\nvar writeStream=require(\"fs\").createWriteStream(\"outpuData.json\");\n\nvar started=false;\ncsvConverter.on(\"record_parsed\",function(rowJSON){\n   if (started){\n      writeStream.write(\",\\n\");\n   }\n   writeStream.write(JSON.stringify(rowJSON));  //write parsed JSON object one by one.\n   if (started==false){\n      started=true;\n   }\n});\n\nwriteStream.write(\"[\\n\"); //write array symbol\n\ncsvConverter.on(\"end_parsed\",function(){\n   writeStream.write(\"\\n]\"); //end array symbol\n});\n    \ncsvConverter.from(readStream);\n```\n\nThe Converter constructor was passed in a \"false\" parameter which will tell the constructor not to combine the final result which would take simlar memory as the file size. The output is constructed line by line through writable stream object.\n",
  "readmeFilename": "readme.md",
  "_id": "csvtojson@0.1.7",
  "dist": {
    "shasum": "819f16f28c9be2dd0a7f28156ddff8002c460266"
  },
  "_from": "csvtojson@0.1.7",
  "_resolved": "https://registry.npmjs.org/csvtojson/-/csvtojson-0.1.7.tgz"
}
